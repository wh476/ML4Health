{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor\n",
    "import demoji\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertweetTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load BERTweet model and tokenizer\n",
    "model_name = \"vinai/bertweet-base\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer = BertweetTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label', 'tweet', 'label_category'], dtype='object')\n",
      "(20620, 3)\n",
      "   label                                              tweet  \\\n",
      "0      0  !!!!! rt @mleew17: boy dats cold...tyga dwn ba...   \n",
      "1      0  !!!!!!! rt @urkindofbrand dawg!!!! rt @80sbaby...   \n",
      "2      0  !!!!!!!!! rt @c_g_anderson: @viva_based she lo...   \n",
      "3      0  !!!!!!!!!!!!! rt @shenikaroberts: the shit you...   \n",
      "4      0  !!!!!!!!!!!!!!!!!!\"@t_madison_x: the shit just...   \n",
      "5      0  !!!!!!\"@__brighterdays: i can not just sit up ...   \n",
      "6      0  !!!!“@selfiequeenbri: cause i'm tired of you b...   \n",
      "7      0  \" & you might not get ya bitch back & thats th...   \n",
      "8      0  \" @rhythmixx_ :hobbies include: fighting maria...   \n",
      "9      0  \" keeks is a bitch she curves everyone \" lol i...   \n",
      "\n",
      "       label_category  \n",
      "0  Offensive Language  \n",
      "1  Offensive Language  \n",
      "2  Offensive Language  \n",
      "3  Offensive Language  \n",
      "4  Offensive Language  \n",
      "5  Offensive Language  \n",
      "6  Offensive Language  \n",
      "7  Offensive Language  \n",
      "8  Offensive Language  \n",
      "9  Offensive Language  \n"
     ]
    }
   ],
   "source": [
    "# Load your dataset with columns 'tweet' and 'categories'\n",
    "dataset = pd.read_csv('./dataset/cleaned_dataset.csv')\n",
    "dataset['label'] = dataset['label'].map({0: 1, 1: 0}) # swap label 0 to label 1 and vice versa\n",
    "print(dataset.columns)\n",
    "print(dataset.shape)\n",
    "print(dataset.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label', 'tweet', 'label_category'], dtype='object')\n",
      "(20620, 3)\n",
      "   label                                              tweet  \\\n",
      "0      0  !!!!! rt @mleew17: boy dats cold...tyga dwn ba...   \n",
      "1      0  !!!!!!! rt @urkindofbrand dawg!!!! rt @80sbaby...   \n",
      "2      0  !!!!!!!!! rt @c_g_anderson: @viva_based she lo...   \n",
      "3      0  !!!!!!!!!!!!! rt @shenikaroberts: the shit you...   \n",
      "4      0  !!!!!!!!!!!!!!!!!!\"@t_madison_x: the shit just...   \n",
      "5      0  !!!!!!\"@__brighterdays: i can not just sit up ...   \n",
      "6      0  !!!!“@selfiequeenbri: cause i'm tired of you b...   \n",
      "7      0  \" & you might not get ya bitch back & thats th...   \n",
      "8      0  \" @rhythmixx_ :hobbies include: fighting maria...   \n",
      "9      0  \" keeks is a bitch she curves everyone \" lol i...   \n",
      "\n",
      "       label_category  \n",
      "0  Offensive Language  \n",
      "1  Offensive Language  \n",
      "2  Offensive Language  \n",
      "3  Offensive Language  \n",
      "4  Offensive Language  \n",
      "5  Offensive Language  \n",
      "6  Offensive Language  \n",
      "7  Offensive Language  \n",
      "8  Offensive Language  \n",
      "9  Offensive Language  \n"
     ]
    }
   ],
   "source": [
    "# # Load and preprocess your dataset\n",
    "# def preprocess_text(text):\n",
    "#     # Use tweet-preprocessor to clean tweets\n",
    "#     cleaned_text = preprocessor.clean(text)\n",
    "#     # Remove emojis\n",
    "#     cleaned_text = remove_emojis(cleaned_text)\n",
    "#     return cleaned_text\n",
    "\n",
    "# def remove_emojis(text):\n",
    "#     return demoji.replace(text, '')\n",
    "\n",
    "# # Preprocess text\n",
    "# dataset['label'] = dataset['label'].map({0: 1, 1: 0}) # swap label 0 to label 1 and vice versa\n",
    "# # dataset['cleaned_tweet'] = dataset['tweet'].apply(preprocess_text)\n",
    "\n",
    "# print(dataset.columns)\n",
    "# print(dataset.shape)\n",
    "# print(dataset.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 12372 (Hate Speech:  886 , Non-Hate Speech:  11486 )\n",
      "Validation set size: 4124 (Hate Speech:  262 , Non-Hate Speech:  3862 )\n",
      "Testing set size: 4124 (Hate Speech:  282 , Non-Hate Speech:  3842 )\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test_temp, y_train, y_test_temp = train_test_split(\n",
    "    dataset['tweet'],  # Features\n",
    "    dataset['label'],  # Labels\n",
    "    test_size=0.4, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split the testing set into validation (50%) and testing (50%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_test_temp,\n",
    "    y_test_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Reset the index to ensure it is consecutive\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_val.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the sizes of each set: Training 60% / Val 20% / Testing 20% \n",
    "print(\"Training set size:\", len(X_train), \"(Hate Speech: \", sum(y_train == 1), \", Non-Hate Speech: \", sum(y_train == 0), \")\")\n",
    "print(\"Validation set size:\", len(X_val), \"(Hate Speech: \", sum(y_val == 1), \", Non-Hate Speech: \", sum(y_val == 0), \")\")\n",
    "print(\"Testing set size:\", len(X_test), \"(Hate Speech: \", sum(y_test == 1), \", Non-Hate Speech: \", sum(y_test == 0), \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'i knw these bitch niggas frm way back... if u was ah pussy in 2000 u ah pussy now!!!'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j5/b206ytkd1f52lmgd91ffpq1r0000gn/T/ipykernel_34954/1477917973.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Use SMOTEENN to balance the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msmote_enn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote_enn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Convert X_train_resampled back to a Series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_train_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_resampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0my_resampled\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m    104\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampling_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         raise ValueError(\n\u001b[1;32m   1189\u001b[0m             \u001b[0;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         )\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1193\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    948\u001b[0m                         )\n\u001b[1;32m    949\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m                 raise ValueError(\n\u001b[1;32m    954\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2082\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2085\u001b[0m         if (\n\u001b[1;32m   2086\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'i knw these bitch niggas frm way back... if u was ah pussy in 2000 u ah pussy now!!!'"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Use SMOTEENN to balance the training data\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train.to_frame(), y_train)\n",
    "\n",
    "# Convert X_train_resampled back to a Series\n",
    "X_train_resampled = X_train_resampled.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(text):\n",
    "    return tokenizer(\n",
    "        text,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "# Tokenize and prepare input data for training set\n",
    "tokenized_train = X_train.apply(tokenize_data)\n",
    "print(\"Training set size: \", len(tokenized_train))\n",
    "print(tokenized_train.head(3))\n",
    "tokenized_val = X_val.apply(tokenize_data)\n",
    "print(\"Validation set size: \", len(tokenized_val))\n",
    "print(tokenized_val.head(3))\n",
    "tokenized_test = X_test.apply(tokenize_data)\n",
    "print(\"Testing set size: \", len(tokenized_test))\n",
    "print(tokenized_test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [input_ids, token_type_ids, attention_mask]\n",
      "1        [input_ids, token_type_ids, attention_mask]\n",
      "2        [input_ids, token_type_ids, attention_mask]\n",
      "3        [input_ids, token_type_ids, attention_mask]\n",
      "4        [input_ids, token_type_ids, attention_mask]\n",
      "                            ...                     \n",
      "12367    [input_ids, token_type_ids, attention_mask]\n",
      "12368    [input_ids, token_type_ids, attention_mask]\n",
      "12369    [input_ids, token_type_ids, attention_mask]\n",
      "12370    [input_ids, token_type_ids, attention_mask]\n",
      "12371    [input_ids, token_type_ids, attention_mask]\n",
      "Name: tweet, Length: 12372, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoader for training set\n",
    "input_ids_train = torch.cat([tokenized_train[i]['input_ids'] for i in range(len(tokenized_train))], dim=0)\n",
    "attention_masks_train = torch.cat([tokenized_train[i]['attention_mask'] for i in range(len(tokenized_train))], dim=0)\n",
    "labels_train = torch.tensor(y_train.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=8, shuffle=True)\n",
    "\n",
    "# Create DataLoader for validation set\n",
    "input_ids_val = torch.cat([tokenized_val[i]['input_ids'] for i in range(len(tokenized_val))], dim=0)\n",
    "attention_masks_val = torch.cat([tokenized_val[i]['attention_mask'] for i in range(len(tokenized_val))], dim=0)\n",
    "labels_val = torch.tensor(y_val.values)\n",
    "\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=8, shuffle=False)\n",
    "\n",
    "# Create DataLoader for testing set\n",
    "input_ids_test = torch.cat([tokenized_test[i]['input_ids'] for i in range(len(tokenized_test))], dim=0)\n",
    "attention_masks_test = torch.cat([tokenized_test[i]['attention_mask'] for i in range(len(tokenized_test))], dim=0)\n",
    "labels_test = torch.tensor(y_test.values)\n",
    "\n",
    "# Create DataLoader for testing set\n",
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "# loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Set up training parameters\n",
    "num_epochs = 5  # You can adjust this based on your requirements\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model and data to the device\n",
    "model.to(device)\n",
    "input_ids_train, attention_masks_train, labels_train = input_ids_train.to(device), attention_masks_train.to(device), labels_train.to(device)\n",
    "input_ids_val, attention_masks_val, labels_val = input_ids_val.to(device), attention_masks_val.to(device), labels_val.to(device)\n",
    "loss_per_epoch = {'train': [], 'val': []}\n",
    "accuracy_per_epoch = {'train': [], 'val': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   0%|          | 1/1547 [00:01<38:25,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   0%|          | 2/1547 [00:03<39:39,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   0%|          | 3/1547 [00:04<38:34,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   0%|          | 4/1547 [00:06<38:24,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   0%|          | 5/1547 [00:07<38:09,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   0%|          | 6/1547 [00:09<39:29,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   0%|          | 7/1547 [00:10<39:16,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|          | 8/1547 [00:12<39:30,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|          | 9/1547 [00:13<38:34,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|          | 10/1547 [00:15<37:49,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|          | 11/1547 [00:16<37:59,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|          | 12/1547 [00:18<38:12,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|          | 13/1547 [00:19<37:55,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|          | 14/1547 [00:21<38:01,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|          | 15/1547 [00:22<39:06,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|          | 16/1547 [00:24<38:57,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|          | 17/1547 [00:25<38:32,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|          | 18/1547 [00:27<38:18,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|          | 19/1547 [00:28<37:47,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|▏         | 20/1547 [00:30<37:35,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|▏         | 21/1547 [00:31<37:13,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 1, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|▏         | 22/1547 [00:33<38:04,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   1%|▏         | 23/1547 [00:34<37:29,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   2%|▏         | 24/1547 [00:36<38:07,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   2%|▏         | 25/1547 [00:37<37:48,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   2%|▏         | 26/1547 [00:38<37:37,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   2%|▏         | 27/1547 [00:40<37:23,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   2%|▏         | 28/1547 [00:41<37:29,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   2%|▏         | 29/1547 [00:43<38:01,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   2%|▏         | 30/1547 [00:44<37:30,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   2%|▏         | 31/1547 [00:46<38:01,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   2%|▏         | 32/1547 [00:48<39:34,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   2%|▏         | 33/1547 [00:49<39:48,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   2%|▏         | 34/1547 [00:51<39:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   2%|▏         | 35/1547 [00:52<38:44,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   2%|▏         | 36/1547 [00:54<39:08,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   2%|▏         | 37/1547 [00:55<39:02,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   2%|▏         | 38/1547 [00:57<39:05,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 39/1547 [00:58<38:25,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 40/1547 [01:00<37:51,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 41/1547 [01:01<37:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 42/1547 [01:03<36:42,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 43/1547 [01:04<36:25,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 44/1547 [01:06<36:39,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 45/1547 [01:07<36:37,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 46/1547 [01:09<38:42,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 47/1547 [01:10<39:34,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 48/1547 [01:12<38:53,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 49/1547 [01:13<38:01,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 50/1547 [01:15<37:29,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 51/1547 [01:16<37:05,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 52/1547 [01:18<39:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 53/1547 [01:20<39:37,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   3%|▎         | 54/1547 [01:21<39:45,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   4%|▎         | 55/1547 [01:23<39:19,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   4%|▎         | 56/1547 [01:24<39:09,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   4%|▎         | 57/1547 [01:26<39:35,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   4%|▎         | 58/1547 [01:28<40:55,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   4%|▍         | 59/1547 [01:30<41:51,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   4%|▍         | 60/1547 [01:31<40:16,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   4%|▍         | 61/1547 [01:33<39:45,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   4%|▍         | 62/1547 [01:34<38:30,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   4%|▍         | 63/1547 [01:36<38:18,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   4%|▍         | 64/1547 [01:37<37:36,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   4%|▍         | 65/1547 [01:39<37:34,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   4%|▍         | 66/1547 [01:40<37:48,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   4%|▍         | 67/1547 [01:42<39:07,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   4%|▍         | 68/1547 [01:43<39:06,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   4%|▍         | 69/1547 [01:45<40:40,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▍         | 70/1547 [01:48<44:55,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▍         | 71/1547 [01:50<47:27,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▍         | 72/1547 [01:51<46:17,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▍         | 73/1547 [01:53<45:15,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▍         | 74/1547 [01:55<44:19,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▍         | 75/1547 [01:57<42:43,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▍         | 76/1547 [01:58<41:40,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▍         | 77/1547 [02:00<40:28,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▌         | 78/1547 [02:01<39:56,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▌         | 79/1547 [02:03<39:12,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▌         | 80/1547 [02:04<39:10,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▌         | 81/1547 [02:06<38:18,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▌         | 82/1547 [02:07<37:33,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▌         | 83/1547 [02:09<37:09,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▌         | 84/1547 [02:11<38:12,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   5%|▌         | 85/1547 [02:12<39:11,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   6%|▌         | 86/1547 [02:14<39:04,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   6%|▌         | 87/1547 [02:15<38:52,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   6%|▌         | 88/1547 [02:17<37:43,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   6%|▌         | 89/1547 [02:18<37:53,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   6%|▌         | 90/1547 [02:20<38:54,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   6%|▌         | 91/1547 [02:22<40:08,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   6%|▌         | 92/1547 [02:24<39:57,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   6%|▌         | 93/1547 [02:25<40:01,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   6%|▌         | 94/1547 [02:27<39:13,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   6%|▌         | 95/1547 [02:28<39:11,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   6%|▌         | 96/1547 [02:30<38:37,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   6%|▋         | 97/1547 [02:32<38:51,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   6%|▋         | 98/1547 [02:33<39:18,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   6%|▋         | 99/1547 [02:35<40:16,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   6%|▋         | 100/1547 [02:37<40:57,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   7%|▋         | 101/1547 [02:38<40:55,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   7%|▋         | 102/1547 [02:40<39:49,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   7%|▋         | 103/1547 [02:42<39:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   7%|▋         | 104/1547 [02:43<39:23,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   7%|▋         | 105/1547 [02:45<40:09,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5:   7%|▋         | 105/1547 [02:46<38:12,  1.59s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Calculate training accuracy\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/adamw.py:187\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    174\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    176\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    177\u001b[0m         group,\n\u001b[1;32m    178\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m         state_steps,\n\u001b[1;32m    185\u001b[0m     )\n\u001b[0;32m--> 187\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/adamw.py:339\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 339\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/adamw.py:472\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m--> 472\u001b[0m     \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(params[i]):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in tqdm(dataloader_train, desc=f'Training Epoch {epoch + 1}/{num_epochs}'):\n",
    "        batch_input_ids, batch_attention_masks, batch_labels = batch\n",
    "        batch_input_ids, batch_attention_masks, batch_labels = (\n",
    "            batch_input_ids.to(device),\n",
    "            batch_attention_masks.to(device),\n",
    "            batch_labels.to(device),\n",
    "        )\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=batch_input_ids,\n",
    "            attention_mask=batch_attention_masks,\n",
    "            labels=batch_labels,\n",
    "        )\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = outputs.loss\n",
    "        # loss = loss_fn(outputs.logits.squeeze(), batch_labels.float())\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, predicted_labels = torch.max(outputs.logits, 1)\n",
    "        print(predicted_labels)\n",
    "        print(batch_labels)\n",
    "        correct_predictions += (predicted_labels == batch_labels).sum().item()\n",
    "        total_samples += batch_labels.size(0)\n",
    "\n",
    "    # Calculate accuracy for the training epoch\n",
    "    accuracy_train = correct_predictions / total_samples\n",
    "    accuracy_per_epoch['train'].append(accuracy_train)\n",
    "\n",
    "    # Calculate average loss for the training epoch\n",
    "    average_loss_train = total_loss / len(dataloader_train)\n",
    "    loss_per_epoch['train'].append(average_loss_train)\n",
    "   \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {average_loss_train}, Train Accuracy: {accuracy_train}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss_val = 0\n",
    "    correct_predictions_val = 0\n",
    "    total_samples_val = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation during validation\n",
    "        for batch_val in tqdm(dataloader_val, desc=f'Validation Epoch {epoch + 1}/{num_epochs}'):\n",
    "            batch_input_ids, batch_attention_masks, batch_labels = batch_val\n",
    "            batch_input_ids, batch_attention_masks, batch_labels = (\n",
    "                batch_input_ids.to(device),\n",
    "                batch_attention_masks.to(device),\n",
    "                batch_labels.to(device),\n",
    "            )\n",
    "            outputs = model(\n",
    "                    input_ids=batch_input_ids,\n",
    "                    attention_mask=batch_attention_masks,\n",
    "                    labels=batch_labels,\n",
    "                )\n",
    "\n",
    "            # loss_val = outputs.loss\n",
    "            loss_val = outputs.loss\n",
    "            total_loss_val += loss_val.item()\n",
    "\n",
    "            _, predicted_labels_val = torch.max(outputs.logits, 1)\n",
    "            correct_predictions_val += (predicted_labels_val == batch_labels).sum().item()\n",
    "            total_samples_val += batch_labels.size(0)\n",
    "\n",
    "    # Calculate accuracy for the validation epoch\n",
    "    accuracy_val = correct_predictions_val / total_samples_val\n",
    "    accuracy_per_epoch['val'].append(accuracy_val)\n",
    "\n",
    "    # Calculate average loss for the validation epoch\n",
    "    average_loss_val = total_loss_val / len(dataloader_val)\n",
    "    loss_per_epoch['val'].append(average_loss_val)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {average_loss_val}, Validation Accuracy: {accuracy_val}\")\n",
    "\n",
    "# Save the trained model (This method is specific to the transformers library and is designed for saving transformer-based models.)\n",
    "# It saves the model in a format that includes the architecture, parameters, and additional information specific to the transformers library.\n",
    "# It provides a higher-level abstraction that is specific to transformer models and allows for easily loading the model using AutoModelForSequenceClassification.from_pretrained later.\n",
    "model.save_pretrained(\"./model/BERTweet model\")\n",
    "tokenizer.save_pretrained(\"./model/BERTweet model\")\n",
    "\n",
    "# Plot the loss values\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Training and Validation Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), loss_per_epoch['train'], label='Training Loss', marker='o', linestyle='-', color='b')\n",
    "plt.plot(range(1, num_epochs + 1), loss_per_epoch['val'], label='Validation Loss', marker='o', linestyle='-', color='r')\n",
    "plt.title('Training and Validation Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Training and Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), accuracy_per_epoch['train'], label='Training Accuracy', marker='o', linestyle='-', color='b')\n",
    "plt.plot(range(1, num_epochs + 1), accuracy_per_epoch['val'], label='Validation Accuracy', marker='o', linestyle='-', color='r')\n",
    "plt.title('Training and Validation Accuracy per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
     ]
    }
   ],
   "source": [
    "# trained model\n",
    "# lr = 5e-5\n",
    "# batch size = 8\n",
    "# epoch = 5\n",
    "# total training time = 331 mins\n",
    "# optimizer = AdamW\n",
    "\n",
    "# Load the BERTweet tokenizer and model for sequence classification\n",
    "model_path = \"./model/BERTweet model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "        Hate Speech       0.00      0.00      0.00       282\n",
      "Offensive Languages       0.93      1.00      0.96      3842\n",
      "\n",
      "           accuracy                           0.93      4124\n",
      "          macro avg       0.47      0.50      0.48      4124\n",
      "       weighted avg       0.87      0.93      0.90      4124\n",
      "\n",
      "13177    1\n",
      "2432     1\n",
      "4252     1\n",
      "11072    1\n",
      "6700     1\n",
      "        ..\n",
      "20091    1\n",
      "9723     1\n",
      "5548     0\n",
      "13021    0\n",
      "10845    1\n",
      "Name: label, Length: 4124, dtype: int64\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_dict = {'Hate Speech': 1, 'Offensive Languages': 0}\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader_test:\n",
    "        input_ids, attention_masks, labels = [tensor.to(device) for tensor in batch]\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_masks)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"BERTweet:\")\n",
    "print(classification_report(y_test, all_preds, target_names=label_dict.keys()))\n",
    "print(y_test)\n",
    "print(all_preds)\n",
    "# Generate confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, all_preds)\n",
    "accuracy_bertweet = accuracy_score(y_test, all_preds)\n",
    "\n",
    "# Display the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 8))\n",
    "# sns.heatmap(conf_mat, annot=True, cmap='Blues', xticklabels=label_dict.keys(), yticklabels=label_dict.keys())\n",
    "sns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='g', xticklabels=label_dict.keys(), yticklabels=label_dict.keys())\n",
    "plt.title(f'Confusion Matrix\\nAccuracy: {accuracy_bertweet:.2f}')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() missing 1 required positional argument: 'output_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m TweetDataset(test_encodings, test_labels)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Fine-tune the model\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./logs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     60\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     63\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     64\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     65\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     66\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtest_dataset\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     69\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() missing 1 required positional argument: 'output_dir'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertweetTokenizer, Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your dataset with columns 'tweet' and 'label'\n",
    "dataset = pd.read_csv('./dataset/cleaned_dataset.csv')\n",
    "\n",
    "# Load BERTweet model and tokenizer\n",
    "model_name = \"vinai/bertweet-base\"\n",
    "tokenizer = BertweetTokenizer.from_pretrained(model_name, normalization=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Preprocess text and split the dataset\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = text.strip()\n",
    "    return cleaned_text\n",
    "\n",
    "dataset['cleaned_tweet'] = dataset['tweet'].apply(preprocess_text)\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    dataset['cleaned_tweet'],\n",
    "    dataset['label'],\n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Tokenize data\n",
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True)\n",
    "\n",
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TweetDataset(train_encodings, train_labels)\n",
    "test_dataset = TweetDataset(test_encodings, test_labels)\n",
    "\n",
    "# Fine-tune the model\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    save_steps=100,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = trainer.predict(test_dataset)\n",
    "predicted_labels = predictions.predictions.argmax(-1)\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
